import os
import shutil
import json
import locale
import sys
from SCons.Script import Import

Import("env")

def minify_json(src, dst):
    """è®€å– JSON ä¸¦å»é™¤ç©ºç™½å¾Œå¯«å…¥ç›®æ¨™è·¯å¾‘ (å£“ç¸®æª”æ¡ˆ)"""
    try:
        with open(src, 'r', encoding='utf-8') as f:
            data = json.load(f)
        with open(dst, 'w', encoding='utf-8') as f:
            # separators=(',', ':') æœƒå»é™¤å¤šé¤˜ç©ºæ ¼èˆ‡æ›è¡Œ
            json.dump(data, f, ensure_ascii=False, separators=(',', ':'))
        return True
    except Exception as e:
        print(f"[Auto-Lang] JSON å£“ç¸®å¤±æ•— {src}: {e}")
        return False

def auto_copy_languages(source, target, env):
    project_dir = env.subst("$PROJECT_DIR")
    lang_dir = os.path.join(project_dir, "lang")
    data_dir = os.path.join(project_dir, "data")

    print("-" * 40)

    if not os.path.exists(lang_dir):
        print("[Auto-Lang] âš ï¸ æ‰¾ä¸åˆ° 'lang' è³‡æ–™å¤¾ï¼Œè·³éã€‚")
        return

    # 0. æƒæå¯ç”¨èªè¨€ä¸¦è©¢å•
    available_langs = set()
    for f in os.listdir(lang_dir):
        if f.startswith("lang_") and f.endswith(".json"):
            parts = f.split('.')[0].split('_')
            if len(parts) >= 2:
                available_langs.add(parts[-1])
    
    print(f"[Auto-Lang] ç™¼ç¾å¯ç”¨èªè¨€: {', '.join(sorted(available_langs))}")

    # 0.1 åµæ¸¬ç³»çµ±èªè¨€ä¸¦è¨­å®šé è¨­å€¼
    default_langs = ['en'] # é è¨­ç¸½æ˜¯åŒ…å«è‹±æ–‡ä½œç‚ºåŸºåº•
    try:
        # å–å¾—ç³»çµ±èªç³»ï¼Œä¾‹å¦‚ ('zh_TW', 'cp950')
        sys_loc = locale.getdefaultlocale()[0]
        if sys_loc:
            sys_loc = sys_loc.lower()
            detected_code = None
            # ç°¡å–®çš„æ˜ å°„é‚è¼¯ï¼šå°‡ç³»çµ±èªç³»å°æ‡‰åˆ°å°ˆæ¡ˆçš„èªè¨€ä»£ç¢¼
            if 'zh' in sys_loc and ('tw' in sys_loc or 'hk' in sys_loc):
                detected_code = 'tw'
            elif 'ru' in sys_loc:
                detected_code = 'ru'
            elif 'ja' in sys_loc:
                detected_code = 'jp'
            elif 'de' in sys_loc:
                detected_code = 'de'
            elif 'es' in sys_loc:
                detected_code = 'es'
            
            # å¦‚æœåµæ¸¬åˆ°çš„èªè¨€å­˜åœ¨æ–¼å¯ç”¨åˆ—è¡¨ä¸­ï¼Œä¸”ä¸æ˜¯è‹±æ–‡(å·²åŠ )ï¼Œå‰‡åŠ å…¥é è¨­å€¼
            if detected_code and detected_code in available_langs and detected_code != 'en':
                default_langs.append(detected_code)
    except:
        pass

    default_str = ', '.join(default_langs)
    print(f"[Auto-Lang] ç³»çµ±åµæ¸¬å»ºè­°: [{default_str}]")

    # æª¢æŸ¥æ˜¯å¦åœ¨äº’å‹•å¼çµ‚ç«¯æ©Ÿä¸­åŸ·è¡Œ (é¿å…åœ¨ CI/CD æˆ–éäº’å‹•ç’°å¢ƒå¡ä½)
    if sys.stdin and sys.stdin.isatty():
        print(f"[Auto-Lang] è«‹è¼¸å…¥è¦æ‰“åŒ…çš„èªè¨€ä»£ç¢¼ (ç”¨é€—è™Ÿåˆ†éš”)ï¼Œç›´æ¥æŒ‰ Enter ä½¿ç”¨å»ºè­°å€¼")
        try:
            user_input = input("è«‹è¼¸å…¥ > ").strip()
        except:
            user_input = ""
    else:
        print(f"[Auto-Lang] éäº’å‹•æ¨¡å¼ (æˆ–ç„¡æ³•è®€å–è¼¸å…¥)ï¼Œè‡ªå‹•ä½¿ç”¨å»ºè­°å€¼")
        user_input = ""

    included_langs = [x.strip() for x in user_input.split(',')] if user_input else default_langs

    print(f"[Auto-Lang] æ­£åœ¨æœ€ä½³åŒ–èªè¨€æª”...")
    print(f"[Auto-Lang] ä¿ç•™èªè¨€æ¸…å–®: {included_langs}")

    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
        print(f"[Auto-Lang] ğŸ“‚ å·²å»ºç«‹ 'data' è³‡æ–™å¤¾")

    # 1. æ¸…ç† data è³‡æ–™å¤¾ä¸­ç¾æœ‰çš„èªè¨€æª” (é˜²æ­¢èˆŠæª”æ®˜ç•™ä½”ç”¨ç©ºé–“)
    # å‡è¨­èªè¨€æª”ä»¥ lang_ æˆ– attributions_ é–‹é ­
    print("[Auto-Lang] --- é–‹å§‹æ¸…ç†èˆŠèªè¨€æª” ---")
    for f in os.listdir(data_dir):
        if (f.startswith("lang_") or f.startswith("attributions_")) and f.endswith(".json"):
            file_path = os.path.join(data_dir, f)
            try:
                os.remove(file_path)
                print(f"[Auto-Lang] ğŸ§¹ å·²åˆªé™¤: {f}")
            except Exception as e:
                print(f"[Auto-Lang] âŒ åˆªé™¤å¤±æ•—: {f} ({e})")
    print("[Auto-Lang] --- æ¸…ç†å®Œæˆ ---")

    # 2. ç¯©é¸ã€å£“ç¸®ä¸¦è¤‡è£½
    copied_count = 0
    total_size = 0
    
    for filename in os.listdir(lang_dir):
        if not filename.endswith(".json"):
            print(f"[Auto-Lang] â­ï¸ è·³éé JSON æª”æ¡ˆ: {filename}")
            continue
            
        # è§£æèªè¨€ä»£ç¢¼ (ä¾‹å¦‚ lang_en.json -> en)
        # é‚è¼¯ï¼šå–æª”åä¸­æœ€å¾Œä¸€å€‹åº•ç·šå¾Œçš„å­—ä¸²ä½œç‚ºä»£ç¢¼
        parts = filename.split('.')[0].split('_')
        if len(parts) < 2: 
            print(f"[Auto-Lang] â“ æª”åæ ¼å¼ä¸ç¬¦ï¼Œè·³é: {filename}")
            continue
        
        lang_code = parts[-1] 
        
        if lang_code in included_langs:
            src = os.path.join(lang_dir, filename)
            dst = os.path.join(data_dir, filename)
            original_size = os.path.getsize(src)
            
            # åŸ·è¡Œå£“ç¸®è¤‡è£½
            if minify_json(src, dst):
                minified_size = os.path.getsize(dst)
                total_size += minified_size
                reduction = original_size - minified_size
                reduction_pct = (reduction / original_size * 100) if original_size > 0 else 0
                print(f"[Auto-Lang] âœ… å·²å£“ç¸®æ‰“åŒ…: {filename} ({original_size} -> {minified_size} bytes, ç¯€çœ {reduction_pct:.1f}%)")
                copied_count += 1
            else:
                # å£“ç¸®å¤±æ•—å‰‡ç›´æ¥è¤‡è£½
                shutil.copy2(src, dst)
                final_size = os.path.getsize(dst)
                total_size += final_size
                print(f"[Auto-Lang] âš ï¸ åƒ…è¤‡è£½ (å£“ç¸®å¤±æ•—): {filename} ({final_size} bytes)")
                copied_count += 1
        else:
            # é€™è£¡å¯ä»¥é¸æ“‡æ˜¯å¦é¡¯ç¤ºè·³éçš„æª”æ¡ˆ
            print(f"[Auto-Lang] â­ï¸ è·³é (ä¸åœ¨ä¿ç•™æ¸…å–®ä¸­): {filename}")

    print(f"[Auto-Lang] å®Œæˆï¼å…±æ‰“åŒ… {copied_count} å€‹æª”æ¡ˆï¼Œç¸½å¤§å°: {total_size} bytes")
    print("-" * 40)

# å°‡æ­¤è…³æœ¬æ›è¼‰åˆ° SPIFFS å»ºç½®æµç¨‹å‰
env.AddPreAction("$BUILD_DIR/spiffs.bin", auto_copy_languages)
env.AddPreAction("uploadfs", auto_copy_languages)
